{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "import orbax.checkpoint as ocp\n",
    "from jax import make_jaxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride = 1, padding = 1, bias = True):\n",
    "    return nn.Conv(features= out_channels,\n",
    "                   kernel_size= (3, 3), \n",
    "                   strides= (stride, stride),\n",
    "                   padding= padding,\n",
    "                   use_bias= bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testit(model, input, key, make = False):\n",
    "    if not isinstance(input, tuple): # handles objects with different no. of inputs UpConv and DownConv\n",
    "        x = (input,)\n",
    "    else:\n",
    "        x = input\n",
    "    key, split_key = jax.random.split(key)\n",
    "    variables = model.init(split_key, *x)\n",
    "    results = model.apply(variables, *x)\n",
    "    print(f\"\\nVariable Shapes : \\n{jax.tree.map(lambda x: x.shape, variables)} \\n\\nResults Shapes: {jax.tree.map(lambda x : x.shape, results)}\")\n",
    "    if make:\n",
    "        print(f\"\\n\\n\\nResults : {results}\")\n",
    "        return make_jaxpr(lambda variables, x: model.apply(variables, x))(variables, x)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'bias': (3,), 'kernel': (3, 3, 1, 3)}} \n",
      "\n",
      "Results Shapes: (1, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(conv3x3(3, 3,), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconv2x2(in_channels, out_channels, mode='transpose'):\n",
    "    '''\n",
    "    Upsample not implemented, need to find alternative\n",
    "    '''\n",
    "    return nn.ConvTranspose(features= out_channels,\n",
    "                            kernel_size= (2, 2),\n",
    "                            strides= (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'bias': (3,), 'kernel': (2, 2, 1, 3)}} \n",
      "\n",
      "Results Shapes: (1, 6, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(upconv2x2(3, 3,), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Conv(features= out_channels, \n",
    "                   kernel_size= 1,\n",
    "                   strides= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'bias': (3,), 'kernel': (1, 3, 3)}} \n",
      "\n",
      "Results Shapes: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(conv1x1(3, 3,), jnp.ones((1, 3)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    in_channels : int\n",
    "    out_channels : int\n",
    "    pooling : bool\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        xskip = self.conv1(x)\n",
    "        x = nn.relu(self.conv2(xskip))\n",
    "        x = nn.relu(self.conv3(x) + xskip)\n",
    "        before_pool = x\n",
    "\n",
    "        if self.pooling:\n",
    "            x = nn.max_pool(x,\n",
    "                            window_shape= (2, 2),\n",
    "                            strides= (2, 2))\n",
    "            \n",
    "        return x, before_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'conv1': {'bias': (3,), 'kernel': (3, 3, 3, 3)}, 'conv2': {'bias': (3,), 'kernel': (3, 3, 3, 3)}, 'conv3': {'bias': (3,), 'kernel': (3, 3, 3, 3)}}} \n",
      "\n",
      "Results Shapes: ((1, 1, 1, 3), (1, 3, 3, 3))\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(DownConv(3, 3, True), jnp.ones((1, 3, 3, 3)), key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    in_channels : int\n",
    "    out_channels : int\n",
    "    merge_mode : str = 'concat'\n",
    "    up_mode : str = 'transpose'\n",
    "\n",
    "    def setup(self):\n",
    "        self.upconv = upconv2x2(self.in_channels, self.out_channels,mode=self.up_mode)\n",
    "        self.conv1 = conv3x3(self.out_channels, self.out_channels) ## refine for flax\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def __call__(self, from_down, from_up):\n",
    "        \n",
    "        from_up = self.upconv(from_up) \n",
    "        if self.merge_mode == 'concat':\n",
    "            x = jnp.concatenate([from_up, from_down], axis = -1) # check axis channel is last for jax\n",
    "        else:\n",
    "            x = from_up + from_down\n",
    "\n",
    "        xskip = self.conv1(x) \n",
    "        x = nn.relu(self.conv2(xskip))\n",
    "        x = nn.relu(self.conv3(x) + xskip)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'conv1': {'bias': (128,), 'kernel': (3, 3, 192, 128)}, 'conv2': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv3': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'upconv': {'bias': (128,), 'kernel': (2, 2, 64, 128)}}} \n",
      "\n",
      "Results Shapes: (1, 4, 4, 128)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "a = jnp.ones((1, 4, 4, 64))\n",
    "b = jnp.ones((1, 2, 2, 64))\n",
    "x = (a, b)\n",
    "testit(UpConv(3, 128), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9589])\n",
      "-0.9589243\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.sin(torch.tensor([5])))\n",
    "print(jnp.sin(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UN(nn.Module):\n",
    "    levels : int\n",
    "    channels : int = 3\n",
    "    depth : int = 5\n",
    "    start_filts : int = 64\n",
    "    up_mode : str = 'transpose'\n",
    "    merge_mode : str = 'add'\n",
    "\n",
    "    def setup(self):\n",
    "        if self.up_mode not in ('transpose', 'upsample'):\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"upsampling. Only \\\"transpose\\\" and \"\n",
    "                             \"\\\"upsample\\\" are allowed.\".format(self.up_mode))\n",
    "        \n",
    "        if self.merge_mode not in ('concat', 'add'):\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for\"\n",
    "                             \"merging up and down paths. \"\n",
    "                             \"Only \\\"concat\\\" and \"\n",
    "                             \"\\\"add\\\" are allowed.\".format(self.up_mode))\n",
    "\n",
    "        if self.up_mode == 'upsample' and self.merge_mode == 'add':\n",
    "            raise ValueError(\"up_mode \\\"upsample\\\" is incompatible \"\n",
    "                             \"with merge_mode \\\"add\\\" at the moment \"\n",
    "                             \"because it doesn't make sense to use \"\n",
    "                             \"nearest neighbour to reduce \"\n",
    "                             \"depth channels (by half).\")\n",
    "        \n",
    "        down_convs = []\n",
    "        up_convs = []\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            ins = self.channels * self.levels if i == 0 else outs\n",
    "            outs = self.start_filts*(2**i)\n",
    "            pooling = True if i < self.depth-1 else False\n",
    "\n",
    "            module = DownConv(ins, outs, pooling=pooling)\n",
    "            down_convs.append(module)\n",
    "        self.down_convs = down_convs\n",
    "\n",
    "        for i in range(self.depth-1):\n",
    "            ins = outs\n",
    "            outs = ins // 2\n",
    "            module = UpConv(ins, outs, up_mode=self.up_mode,merge_mode=self.merge_mode)\n",
    "            up_convs.append(module)\n",
    "        self.up_convs = up_convs\n",
    "\n",
    "        self.conv_final = conv1x1(outs, self.channels)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        stack = None\n",
    "        factor = 10.0\n",
    "        for i in range (self.levels):\n",
    "            scale = x.copy()*(factor**(-i))\n",
    "            scale = jnp.sin(scale)\n",
    "            if stack is None:\n",
    "                stack = scale\n",
    "            else:\n",
    "                stack = jnp.concatenate([stack,scale],axis = -1)\n",
    "        \n",
    "        x = stack\n",
    "        \n",
    "        encoder_outs = []\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x, before_pool = module(x)\n",
    "            encoder_outs.append(before_pool)\n",
    "\n",
    "        for i, module in enumerate(self.up_convs):\n",
    "            before_pool = encoder_outs[-(i+2)]\n",
    "            x = module(before_pool, x)\n",
    "        \n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 05:35:32.337598: W external/xla/xla/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'conv_final': {'bias': (3,), 'kernel': (1, 64, 3)}, 'down_convs_0': {'conv1': {'bias': (64,), 'kernel': (3, 3, 30, 64)}, 'conv2': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'conv3': {'bias': (64,), 'kernel': (3, 3, 64, 64)}}, 'down_convs_1': {'conv1': {'bias': (128,), 'kernel': (3, 3, 64, 128)}, 'conv2': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv3': {'bias': (128,), 'kernel': (3, 3, 128, 128)}}, 'down_convs_2': {'conv1': {'bias': (256,), 'kernel': (3, 3, 128, 256)}, 'conv2': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'conv3': {'bias': (256,), 'kernel': (3, 3, 256, 256)}}, 'down_convs_3': {'conv1': {'bias': (512,), 'kernel': (3, 3, 256, 512)}, 'conv2': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'conv3': {'bias': (512,), 'kernel': (3, 3, 512, 512)}}, 'down_convs_4': {'conv1': {'bias': (1024,), 'kernel': (3, 3, 512, 1024)}, 'conv2': {'bias': (1024,), 'kernel': (3, 3, 1024, 1024)}, 'conv3': {'bias': (1024,), 'kernel': (3, 3, 1024, 1024)}}, 'up_convs_0': {'conv1': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'conv2': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'conv3': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'upconv': {'bias': (512,), 'kernel': (2, 2, 1024, 512)}}, 'up_convs_1': {'conv1': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'conv2': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'conv3': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'upconv': {'bias': (256,), 'kernel': (2, 2, 512, 256)}}, 'up_convs_2': {'conv1': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv2': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv3': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'upconv': {'bias': (128,), 'kernel': (2, 2, 256, 128)}}, 'up_convs_3': {'conv1': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'conv2': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'conv3': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'upconv': {'bias': (64,), 'kernel': (2, 2, 128, 64)}}}} \n",
      "\n",
      "Results Shapes: (1, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "a = jnp.ones((1, 128, 128, 3))\n",
    "# b = jnp.ones((1, 3, 3, 64))\n",
    "x = a\n",
    "testit(UN(levels= 10), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photonLoss(result, target):\n",
    "    expEnergy = jnp.exp(result)\n",
    "    perImage = -jnp.mean(result*target, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.],\n",
       "         [2.],\n",
       "         [3.]],\n",
       "\n",
       "        [[4.],\n",
       "         [5.],\n",
       "         [6.]],\n",
       "\n",
       "        [[7.],\n",
       "         [8.],\n",
       "         [9.]]]])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.arange(9) + 1.\n",
    "x.reshape((1, 3, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_result = torch.from_numpy(x)\n",
    "dummy_target = torch.from_numpy(np.ones_like(x.reshape((1, 3, 3, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photonLossTorch(result, target):\n",
    "        expEnergy = torch.exp(result)\n",
    "        return -torch.mean(result*target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5., dtype=torch.float64)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photonLossTorch(dummy_result, dummy_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
