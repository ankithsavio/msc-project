{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from flax import nnx\n",
    "import orbax.checkpoint as ocp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "  def __init__(self, din: int, dout: int, *, rngs: nnx.Rngs):\n",
    "    key = rngs.params()\n",
    "    self.w = nnx.Param(jax.random.uniform(key, (din, dout)))\n",
    "    self.b = nnx.Param(jnp.zeros((dout,)))\n",
    "    self.din, self.dout = din, dout\n",
    "\n",
    "  def __call__(self, x: jax.Array):\n",
    "    return x @ self.w + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.9137444, 2.068491 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Linear(din = 3, dout = 2, rngs=nnx.Rngs(params=0))\n",
    "model(x = jnp.ones((1, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "\n",
    "        def conv3x3(in_channels, out_channels, stride=1, \n",
    "            padding=1, bias=True, groups=1):    \n",
    "                \n",
    "        return nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=bias,\n",
    "                groups=groups)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride = 1, padding = 1, bias = True):\n",
    "    return nnx.Conv(in_features= in_channels, \n",
    "                    out_features= out_channels, \n",
    "                    kernel_size= 3, \n",
    "                    strides= stride, \n",
    "                    padding= padding, \n",
    "                    use_bias= bias,\n",
    "                    rngs= nnx.Rngs(params=jax.random.key(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconv2x2(in_channels, out_channels, mode='transpose'):\n",
    "    '''\n",
    "    Upsample not implemented, need to find alternative\n",
    "    '''\n",
    "    return nnx.ConvTranspose(in_features= in_channels,\n",
    "                                          out_features= out_channels,\n",
    "                                          kernel_size= 2,\n",
    "                                          strides= 2,\n",
    "                                          rngs= nnx.Rngs(params=jax.random.key(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels):\n",
    "    return nnx.Conv(in_features= in_channels, \n",
    "                    out_features= out_channels, \n",
    "                    kernel_size= 1, \n",
    "                    strides= 1,\n",
    "                    rngs= nnx.Rngs(params=jax.random.key(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.12897272,  0.27571398,  1.1490479 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.ones((1, 3))\n",
    "conv3x3(3, 3)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnx.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(nnx.Module):\n",
    " \n",
    "    def __init__(self, in_channels, out_channels, pooling = True):\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "        # if self.pooling:\n",
    "        #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        xskip = self.conv1(x)\n",
    "        x = nnx.relu(self.conv2(xskip))\n",
    "        x = nnx.relu(self.conv3(x) + xskip)\n",
    "        # x = F.dropout(x)\n",
    "        before_pool = x\n",
    "        x = jax.lax.cond(self.pooling, \n",
    "                         nnx.max_pool(x, window_shape= (2, 2), strides= (2, 2)),\n",
    "                         x)\n",
    "        # if self.pooling:\n",
    "        #     x = nnx.max_pool(x, window_shape= (2, 2), strides= (2, 2))\n",
    "        return x, before_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv(nnx.Module):\n",
    "   \n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                 merge_mode='concat', up_mode='transpose'):\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.merge_mode = merge_mode\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.upconv = upconv2x2(self.in_channels, self.out_channels, \n",
    "            mode=self.up_mode)\n",
    "\n",
    "        self.conv1 = jax.lax.cond(self.merge_mode == 'concat',\n",
    "                                  conv3x3(2*self.out_channels, self.out_channels),\n",
    "                                  conv3x3(self.out_channels, self.out_channels))\n",
    "        \n",
    "        # if self.merge_mode == 'concat':\n",
    "        #     self.conv1 = conv3x3(2*self.out_channels, self.out_channels)\n",
    "        # else:\n",
    "        #     self.conv1 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "\n",
    "    def __call__(self, from_down, from_up):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            from_down: tensor from the encoder pathway\n",
    "            from_up: upconv'd tensor from the decoder pathway\n",
    "        \"\"\"\n",
    "        from_up = self.upconv(from_up)\n",
    "        x = jax.lax.cond(self.merge_mode == 'concat',\n",
    "                         jnp.concatenate([from_up, from_down], axis = 1),\n",
    "                         from_up + from_down)\n",
    "        \n",
    "        # if self.merge_mode == 'concat':\n",
    "        #     x = jnp.concatenate([from_up, from_down], axis = 1) # check axis channel is last for jax\n",
    "        # else:\n",
    "        #     x = from_up + from_down\n",
    "\n",
    "        xskip = self.conv1(x)\n",
    "        x = nnx.relu(self.conv2(xskip))\n",
    "        x = nnx.relu(self.conv3(x) + xskip)\n",
    "        # x = F.dropout(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
