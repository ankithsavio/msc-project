{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "import orbax.checkpoint as ocp\n",
    "from jax import make_jaxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride = 1, padding = 1, bias = True):\n",
    "    return nn.Conv(features= out_channels,\n",
    "                   kernel_size= (3, 3), \n",
    "                   strides= (stride, stride),\n",
    "                   padding= padding,\n",
    "                   use_bias= bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testit(model, input, key, make = False):\n",
    "    if not isinstance(input, tuple): # handles objects with different no. of inputs UpConv and DownConv\n",
    "        x = (input,)\n",
    "    else:\n",
    "        x = input\n",
    "    key, split_key = jax.random.split(key)\n",
    "    variables = model.init(split_key, *x)\n",
    "    results = model.apply(variables, *x)\n",
    "    print(f\"\\nVariable Shapes : \\n{jax.tree.map(lambda x: x.shape, variables)} \\n\\nResults Shapes: {jax.tree.map(lambda x : x.shape, results)}\")\n",
    "    if make:\n",
    "        print(f\"\\n\\n\\nResults : {results}\")\n",
    "        return make_jaxpr(lambda variables, x: model.apply(variables, x))(variables, x)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(conv3x3(3, 3,), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconv2x2(in_channels, out_channels, mode='transpose'):\n",
    "    '''\n",
    "    Upsample not implemented, need to find alternative\n",
    "    '''\n",
    "    return nn.ConvTranspose(features= out_channels,\n",
    "                            kernel_size= (2, 2),\n",
    "                            strides= (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(upconv2x2(3, 3,), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Conv(features= out_channels, \n",
    "                   kernel_size= 1,\n",
    "                   strides= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(conv1x1(3, 3,), jnp.ones((1, 3)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    in_channels : int\n",
    "    out_channels : int\n",
    "    pooling : bool\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        xskip = self.conv1(x)\n",
    "        x = nn.relu(self.conv2(xskip))\n",
    "        x = nn.relu(self.conv3(x) + xskip)\n",
    "        before_pool = x\n",
    "\n",
    "        if self.pooling:\n",
    "            x = nn.max_pool(x,\n",
    "                            window_shape= (2, 2),\n",
    "                            strides= (2, 2))\n",
    "            \n",
    "        return x, before_pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(DownConv(3, 3, True), jnp.ones((1, 3, 3, 3)), key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    in_channels : int\n",
    "    out_channels : int\n",
    "    merge_mode : str = 'concat'\n",
    "    up_mode : str = 'transpose'\n",
    "\n",
    "    def setup(self):\n",
    "        self.upconv = upconv2x2(self.in_channels, self.out_channels,mode=self.up_mode)\n",
    "        self.conv1 = conv3x3(self.out_channels, self.out_channels) ## refine for flax\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def __call__(self, from_down, from_up):\n",
    "        \n",
    "        from_up = self.upconv(from_up) \n",
    "        if self.merge_mode == 'concat':\n",
    "            x = jnp.concatenate([from_up, from_down], axis = -1) # check axis channel is last for jax\n",
    "        else:\n",
    "            x = from_up + from_down\n",
    "\n",
    "        xskip = self.conv1(x) \n",
    "        x = nn.relu(self.conv2(xskip))\n",
    "        x = nn.relu(self.conv3(x) + xskip)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        a = jnp.ones((1, 4, 4, 64))\n",
    "        b = jnp.ones((1, 2, 2, 64))\n",
    "        x = (a, b)\n",
    "        testit(UpConv(3, 128), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9589])\n",
      "-0.9589243\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.sin(torch.tensor([5])))\n",
    "print(jnp.sin(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UN(nn.Module):\n",
    "    levels : int\n",
    "    channels : int = 3\n",
    "    depth : int = 5\n",
    "    start_filts : int = 64\n",
    "    up_mode : str = 'transpose'\n",
    "    merge_mode : str = 'add'\n",
    "\n",
    "    def setup(self):\n",
    "        if self.up_mode not in ('transpose', 'upsample'):\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"upsampling. Only \\\"transpose\\\" and \"\n",
    "                             \"\\\"upsample\\\" are allowed.\".format(self.up_mode))\n",
    "        \n",
    "        if self.merge_mode not in ('concat', 'add'):\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for\"\n",
    "                             \"merging up and down paths. \"\n",
    "                             \"Only \\\"concat\\\" and \"\n",
    "                             \"\\\"add\\\" are allowed.\".format(self.up_mode))\n",
    "\n",
    "        if self.up_mode == 'upsample' and self.merge_mode == 'add':\n",
    "            raise ValueError(\"up_mode \\\"upsample\\\" is incompatible \"\n",
    "                             \"with merge_mode \\\"add\\\" at the moment \"\n",
    "                             \"because it doesn't make sense to use \"\n",
    "                             \"nearest neighbour to reduce \"\n",
    "                             \"depth channels (by half).\")\n",
    "        \n",
    "        down_convs = []\n",
    "        up_convs = []\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            ins = self.channels * self.levels if i == 0 else outs\n",
    "            outs = self.start_filts*(2**i)\n",
    "            pooling = True if i < self.depth-1 else False\n",
    "\n",
    "            module = DownConv(ins, outs, pooling=pooling)\n",
    "            down_convs.append(module)\n",
    "        self.down_convs = down_convs\n",
    "\n",
    "        for i in range(self.depth-1):\n",
    "            ins = outs\n",
    "            outs = ins // 2\n",
    "            module = UpConv(ins, outs, up_mode=self.up_mode,merge_mode=self.merge_mode)\n",
    "            up_convs.append(module)\n",
    "        self.up_convs = up_convs\n",
    "\n",
    "        self.conv_final = conv1x1(outs, self.channels)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        stack = None\n",
    "        factor = 10.0\n",
    "        for i in range (self.levels):\n",
    "            scale = x.copy()*(factor**(-i))\n",
    "            scale = jnp.sin(scale)\n",
    "            if stack is None:\n",
    "                stack = scale\n",
    "            else:\n",
    "                stack = jnp.concatenate([stack,scale],axis = -1)\n",
    "        \n",
    "        x = stack\n",
    "        \n",
    "        encoder_outs = []\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x, before_pool = module(x)\n",
    "            encoder_outs.append(before_pool)\n",
    "\n",
    "        for i, module in enumerate(self.up_convs):\n",
    "            before_pool = encoder_outs[-(i+2)]\n",
    "            x = module(before_pool, x)\n",
    "        \n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        a = jnp.ones((1, 128, 128, 3))\n",
    "        # b = jnp.ones((1, 3, 3, 64))\n",
    "        x = a\n",
    "        testit(UN(levels= 10), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photonLoss(result, target):\n",
    "        expEnergy = jnp.exp(result)\n",
    "        perImage = -jnp.mean(result*target, axis = (-1, -2, -3), keepdims=True)\n",
    "        perImage += jnp.log(jnp.mean(expEnergy, axis = (-1, -2, -3), keepdims= True))*jnp.mean(target, axis = (-1, -2, -3), keepdims= True)\n",
    "        return jnp.mean(perImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/c/Users/ankit/Desktop/Msc AIML/msc-project/GAP/gap')\n",
    "# from BinomDataset import BinomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tifffile import imread, imsave\n",
    "import numpy as np\n",
    "from BinomDataset_JAX import BinomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    labels = np.array(transposed_data[1])\n",
    "    imgs = np.stack(transposed_data[0])\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((imread('/mnt/c/Users/ankit/Desktop/Msc AIML/Data/convallaria/trainingDataGT.tif'), imread('/mnt/c/Users/ankit/Desktop/Msc AIML/Data/convallaria/testDataGT.tif')))\n",
    "minpsnr = -40\n",
    "maxpsnr = -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinomDataset(data[:round(data.shape[0]*0.9)], 256, minpsnr, maxpsnr)\n",
    "val_dataset = BinomDataset(data[round(data.shape[0]*0.9):], 256, minpsnr, maxpsnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size= 1, shuffle = True, drop_last= True, pin_memory= False, num_workers= 12, collate_fn= collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size= 1, shuffle= False, drop_last= False, pin_memory= False, num_workers= 12, collate_fn= collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'clone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'clone'"
     ]
    }
   ],
   "source": [
    "np.random.randint(128, 128 + 10.).clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
