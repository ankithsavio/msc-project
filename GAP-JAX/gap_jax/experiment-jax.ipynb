{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "import orbax.checkpoint as ocp\n",
    "from jax import make_jaxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride = 1, padding = 1, bias = True):\n",
    "    return nn.Conv(features= out_channels,\n",
    "                   kernel_size= (3, 3), \n",
    "                   strides= (stride, stride),\n",
    "                   padding= padding,\n",
    "                   use_bias= bias,\n",
    "                   kernel_init= nn.initializers.xavier_normal(),\n",
    "                   bias_init= nn.initializers.constant(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testit(model, input, key, make = False):\n",
    "    if not isinstance(input, tuple): # handles objects with different no. of inputs - UpConv and DownConv\n",
    "        x = (input,)\n",
    "    else:\n",
    "        x = input\n",
    "    key, split_key = jax.random.split(key)\n",
    "    variables = model.init(split_key, *x)\n",
    "    results = model.apply(variables, *x)\n",
    "    print(f\"\\nVariable Shapes : \\n{jax.tree.map(lambda x: x.shape, variables)} \\n\\nResults Shapes: {jax.tree.map(lambda x : x.shape, results)}\")\n",
    "    if make:\n",
    "        print(f\"\\n\\n\\nResults : {results}\")\n",
    "        return make_jaxpr(lambda variables, *x: model.apply(variables, *x))(variables, *x)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(conv3x3(3, 3,), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'bias': (3,), 'kernel': (3, 3, 1, 3)}} \n",
      "\n",
      "Results Shapes: (1, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(conv3x3(3, 3,), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Conv(features= out_channels, \n",
    "                   kernel_size= 1,\n",
    "                   strides= 1,\n",
    "                   kernel_init= nn.initializers.xavier_normal(),\n",
    "                   bias_init= nn.initializers.constant(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1, 32, 32, 1)\n",
    "_, h, w = shape[:-1]\n",
    "h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    method : str = 'bilinear'\n",
    "    scale : int = 2\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        shape = x.shape\n",
    "        shape = (shape[0], shape[1]*self.scale, shape[2]*self.scale, shape[3])\n",
    "        return jax.image.resize(image = x, shape = shape, method = self.method)\n",
    "\n",
    "def upconv2x2(in_channels, out_channels, mode='transpose'):\n",
    "    '''\n",
    "    Upsample not implemented, need to find alternative\n",
    "    '''\n",
    "    if mode == 'transpose':\n",
    "        return nn.ConvTranspose(features= out_channels,\n",
    "                            kernel_size= (2, 2),\n",
    "                            strides= (2, 2))\n",
    "    else:\n",
    "        return nn.Sequential([Upsample(method = 'bilinear', scale = 2),\n",
    "                              conv1x1(in_channels, out_channels)])\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'bias': (3,), 'kernel': (2, 2, 1, 3)}} \n",
      "\n",
      "Results Shapes: (1, 6, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(upconv2x2(3, 3, mode = 'transpose'), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'layers_1': {'bias': (3,), 'kernel': (1, 1, 3)}}} \n",
      "\n",
      "Results Shapes: (1, 6, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "testit(upconv2x2(3, 3, mode = 'bilinear'), jnp.ones((1, 3, 3, 1)), key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(conv1x1(3, 3,), jnp.ones((1, 3)), key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    in_channels : int\n",
    "    out_channels : int\n",
    "    pooling : bool\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        xskip = self.conv1(x)\n",
    "        x = nn.relu(self.conv2(xskip))\n",
    "        x = nn.relu(self.conv3(x) + xskip)\n",
    "        before_pool = x\n",
    "\n",
    "        if self.pooling:\n",
    "            x = nn.max_pool(x,\n",
    "                            window_shape= (2, 2),\n",
    "                            strides= (2, 2))\n",
    "            \n",
    "        return x, before_pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        testit(DownConv(3, 3, True), jnp.ones((1, 3, 3, 3)), key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    in_channels : int\n",
    "    out_channels : int\n",
    "    merge_mode : str = 'concat'\n",
    "    up_mode : str = 'transpose'\n",
    "\n",
    "    def setup(self):\n",
    "        self.upconv = upconv2x2(self.in_channels, self.out_channels,mode=self.up_mode)\n",
    "        self.conv1 = conv3x3(self.out_channels, self.out_channels) ## refine for flax\n",
    "        self.conv2 = conv3x3(self.out_channels, self.out_channels)\n",
    "        self.conv3 = conv3x3(self.out_channels, self.out_channels)\n",
    "\n",
    "    def __call__(self, from_down, from_up):\n",
    "        \n",
    "        from_up = self.upconv(from_up) \n",
    "        if self.merge_mode == 'concat':\n",
    "            x = jnp.concatenate([from_up, from_down], axis = -1) # check axis channel is last for jax\n",
    "        else:\n",
    "            x = from_up + from_down\n",
    "\n",
    "        xskip = self.conv1(x) \n",
    "        x = nn.relu(self.conv2(xskip))\n",
    "        x = nn.relu(self.conv3(x) + xskip)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'conv1': {'bias': (128,), 'kernel': (3, 3, 192, 128)}, 'conv2': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv3': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'upconv': {'bias': (128,), 'kernel': (2, 2, 64, 128)}}} \n",
      "\n",
      "Results Shapes: (1, 4, 4, 128)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "a = jnp.ones((1, 4, 4, 64))\n",
    "b = jnp.ones((1, 2, 2, 64))\n",
    "x = (a, b)\n",
    "testit(UpConv(3, 128), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        a = jnp.ones((1, 4, 4, 64))\n",
    "        b = jnp.ones((1, 2, 2, 64))\n",
    "        x = (a, b)\n",
    "        testit(UpConv(3, 128), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9589])\n",
      "-0.9589243\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.sin(torch.tensor([5])))\n",
    "print(jnp.sin(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Xavier Init to the model by passing the arguments for each module in the [UN](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial4/Optimization_and_Initialization.html#:~:text=kernel_init%20%3A%20Callable%20%3D%20nn.linear.default_kernel_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [LR Scheduler](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial5/Inception_ResNet_DenseNet.html#:~:text=of%20the%20training-,lr_schedule,-%3D%20optax.) \n",
    "\n",
    "#### ReduceONPlateaur available in optax\n",
    "\n",
    "#### [Clip Gradients](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial6/Transformers_and_MHAttention.html#:~:text=optimizer%20%3D%20optax.chain(%0A%20%20%20%20%20%20%20%20%20%20%20%20optax.clip_by_global_norm(1.0)%2C%20%20%23%20Clip%20gradients%20at%20norm%201%0A%20%20%20%20%20%20%20%20%20%20%20%20optax.adam(lr_schedule)%0A%20%20%20%20%20%20%20%20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UN(nn.Module):\n",
    "    levels : int\n",
    "    channels : int = 3\n",
    "    depth : int = 5\n",
    "    start_filts : int = 64\n",
    "    up_mode : str = 'transpose'\n",
    "    merge_mode : str = 'add'\n",
    "\n",
    "    def setup(self):\n",
    "        if self.up_mode not in ('transpose', 'upsample'):\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"upsampling. Only \\\"transpose\\\" and \"\n",
    "                             \"\\\"upsample\\\" are allowed.\".format(self.up_mode))\n",
    "        \n",
    "        if self.merge_mode not in ('concat', 'add'):\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for\"\n",
    "                             \"merging up and down paths. \"\n",
    "                             \"Only \\\"concat\\\" and \"\n",
    "                             \"\\\"add\\\" are allowed.\".format(self.up_mode))\n",
    "\n",
    "        if self.up_mode == 'upsample' and self.merge_mode == 'add':\n",
    "            raise ValueError(\"up_mode \\\"upsample\\\" is incompatible \"\n",
    "                             \"with merge_mode \\\"add\\\" at the moment \"\n",
    "                             \"because it doesn't make sense to use \"\n",
    "                             \"nearest neighbour to reduce \"\n",
    "                             \"depth channels (by half).\")\n",
    "        \n",
    "        down_convs = []\n",
    "        up_convs = []\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            ins = self.channels * self.levels if i == 0 else outs\n",
    "            outs = self.start_filts*(2**i)\n",
    "            pooling = True if i < self.depth-1 else False\n",
    "\n",
    "            module = DownConv(ins, outs, pooling=pooling)\n",
    "            down_convs.append(module)\n",
    "        self.down_convs = down_convs\n",
    "\n",
    "        for i in range(self.depth-1):\n",
    "            ins = outs\n",
    "            outs = ins // 2\n",
    "            module = UpConv(ins, outs, up_mode=self.up_mode,merge_mode=self.merge_mode)\n",
    "            up_convs.append(module)\n",
    "        self.up_convs = up_convs\n",
    "\n",
    "        self.conv_final = conv1x1(outs, self.channels)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        stack = None\n",
    "        factor = 10.0\n",
    "        for i in range (self.levels):\n",
    "            scale = x.copy()*(factor**(-i))\n",
    "            scale = jnp.sin(scale)\n",
    "            if stack is None:\n",
    "                stack = scale\n",
    "            else:\n",
    "                stack = jnp.concatenate([stack,scale],axis = -1)\n",
    "        \n",
    "        x = stack\n",
    "        \n",
    "        encoder_outs = []\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x, before_pool = module(x)\n",
    "            encoder_outs.append(before_pool)\n",
    "\n",
    "        for i, module in enumerate(self.up_convs):\n",
    "            before_pool = encoder_outs[-(i+2)]\n",
    "            x = module(before_pool, x)\n",
    "        \n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def photonLoss(self, result, target):\n",
    "        expEnergy = jnp.exp(result)\n",
    "        perImage = -jnp.mean(result*target, axis = (-1, -2, -3), keepdims=True)\n",
    "        perImage += jnp.log(jnp.mean(expEnergy, axis = (-1, -2, -3), keepdims= True))*jnp.mean(target, axis = (-1, -2, -3), keepdims= True)\n",
    "        return jnp.mean(perImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        key, split_key = jax.random.split(key)\n",
    "        a = jnp.ones((1, 128, 128, 3))\n",
    "        # b = jnp.ones((1, 3, 3, 64))\n",
    "        x = a\n",
    "        testit(UN(levels= 10), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Shapes : \n",
      "{'params': {'conv_final': {'bias': (3,), 'kernel': (1, 64, 3)}, 'down_convs_0': {'conv1': {'bias': (64,), 'kernel': (3, 3, 30, 64)}, 'conv2': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'conv3': {'bias': (64,), 'kernel': (3, 3, 64, 64)}}, 'down_convs_1': {'conv1': {'bias': (128,), 'kernel': (3, 3, 64, 128)}, 'conv2': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv3': {'bias': (128,), 'kernel': (3, 3, 128, 128)}}, 'down_convs_2': {'conv1': {'bias': (256,), 'kernel': (3, 3, 128, 256)}, 'conv2': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'conv3': {'bias': (256,), 'kernel': (3, 3, 256, 256)}}, 'down_convs_3': {'conv1': {'bias': (512,), 'kernel': (3, 3, 256, 512)}, 'conv2': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'conv3': {'bias': (512,), 'kernel': (3, 3, 512, 512)}}, 'down_convs_4': {'conv1': {'bias': (1024,), 'kernel': (3, 3, 512, 1024)}, 'conv2': {'bias': (1024,), 'kernel': (3, 3, 1024, 1024)}, 'conv3': {'bias': (1024,), 'kernel': (3, 3, 1024, 1024)}}, 'up_convs_0': {'conv1': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'conv2': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'conv3': {'bias': (512,), 'kernel': (3, 3, 512, 512)}, 'upconv': {'bias': (512,), 'kernel': (2, 2, 1024, 512)}}, 'up_convs_1': {'conv1': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'conv2': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'conv3': {'bias': (256,), 'kernel': (3, 3, 256, 256)}, 'upconv': {'bias': (256,), 'kernel': (2, 2, 512, 256)}}, 'up_convs_2': {'conv1': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv2': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'conv3': {'bias': (128,), 'kernel': (3, 3, 128, 128)}, 'upconv': {'bias': (128,), 'kernel': (2, 2, 256, 128)}}, 'up_convs_3': {'conv1': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'conv2': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'conv3': {'bias': (64,), 'kernel': (3, 3, 64, 64)}, 'upconv': {'bias': (64,), 'kernel': (2, 2, 128, 64)}}}} \n",
      "\n",
      "Results Shapes: (1, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "key, split_key = jax.random.split(key)\n",
    "a = jnp.ones((1, 128, 128, 3))\n",
    "# b = jnp.ones((1, 3, 3, 64))\n",
    "x = a\n",
    "testit(UN(levels= 10), input = x, key = key, make = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photonLoss(result, target):\n",
    "        expEnergy = jnp.exp(result)\n",
    "        perImage = -jnp.mean(result*target, axis = (-1, -2, -3), keepdims=True)\n",
    "        perImage += jnp.log(jnp.mean(expEnergy, axis = (-1, -2, -3), keepdims= True))*jnp.mean(target, axis = (-1, -2, -3), keepdims= True)\n",
    "        return jnp.mean(perImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/c/Users/ankit/Desktop/Msc AIML/msc-project/GAP/gap')\n",
    "# from BinomDatasetv4 import BinomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tifffile import imread, imsave\n",
    "import numpy as np\n",
    "from BinomDataset_JAX import BinomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((imread('/mnt/c/Users/ankit/Desktop/Msc AIML/Data/convallaria/trainingDataGT.tif'), imread('/mnt/c/Users/ankit/Desktop/Msc AIML/Data/convallaria/testDataGT.tif')))\n",
    "minpsnr = -40\n",
    "maxpsnr = -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinomDataset(data[:round(data.shape[0]*0.9)], 256, minpsnr, maxpsnr)\n",
    "val_dataset = BinomDataset(data[round(data.shape[0]*0.9):], 256, minpsnr, maxpsnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader forcefully changes the images to torch tensor, use collate to change it to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return np.array(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size= 1, shuffle = True, drop_last= True, pin_memory= False, num_workers= 12, collate_fn= collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size= 1, shuffle= False, drop_last= False, pin_memory= False, num_workers= 12, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = next(iter(train_loader))[:,:,:,-1:]\n",
    "# np.array(img).shape\n",
    "# img[:,:,:,-1:].shape\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0bde121690>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAGiCAYAAABQ9UnfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1J0lEQVR4nO3dfXhTdYIv8O/JyUtfSENfk6YtpbwUlFbUgtCOL+BLlR1ExpkVddeBXa87zgB7e8FxZLx3xXlmYXSuuM9eRndeXN9GF+9zB8Rd0Zk6QB2mVGtFBQahSIEWmhZKSfqaNCe/+0fHjIVSmjbJLyf5fp4njzQ5Sb49pv32/M45v6MIIQSIiIh0xCA7ABERUahYXkREpDssLyIi0h2WFxER6Q7Li4iIdIflRUREusPyIiIi3WF5ERGR7rC8iIhId1heRESkO1LL67nnnkNRURGSkpJQVlaGP/zhDzLjEBGRTkgrrzfeeANVVVV4/PHHsW/fPtxwww1YtGgRTp48KSsSERHphCJrYt558+bh2muvxfPPPx+874orrsDSpUuxceNGGZGIiEgnjDLe1OfzoaGhAY899tiQ+ysrK1FbW3vR8l6vF16vN/h1IBDAuXPnkJmZCUVRIp6XiIjCSwiBrq4uOJ1OGAyhDwJKKa+zZ89C0zTY7fYh99vtdrhcrouW37hxI5588sloxSMioihpbm5Gfn5+yM+TUl5funCrSQgx7JbUunXrsGbNmuDXbrcbkyZNwvX4KxhhinhOIj1TjEYYMtIRONcJ4ffLjhOT1KwsdJVPhnuqCufmBq6nKPBjAHuwA1ardUzPl1JeWVlZUFX1oq2s9vb2i7bGAMBiscBisVx0vxEmGBWWF9FI1KIiHPmuHcU/PwPtyBey48QcxWRGU9WVsDdoKPjXekAoAH+vRN6fj7YY664fKUcbms1mlJWVobq6esj91dXVqKiokBGJKG6J1nZM29ID0douO0pMEv4BFG31wPrRKYAXltcNacOGa9aswQMPPIA5c+agvLwcv/jFL3Dy5Ek8/PDDsiIRxaVATw9Qvx/8tXwJQkDsOwgOFOqLtPJatmwZOjo68KMf/Qitra0oKSnBjh07UFhYKCsSERHphLTzvMbD4/HAZrNhAe7iPi8iIh3yiwHsxna43W6kpaWF/HzObUiUINRZM6AWT5Udg2KMmpUJZW4pFJNZdpSQsLyIEkTLHZloW5gjOwbFGP/0fHzx1xNgSJsgO0pIpJ7nRUTRk//vhwARgCY7CMUUw8efY/rRNGjnOmVHCQnLiyhBaJ36+uVE0SG8XmhnzsiOEbK4HzY0JCXpbiyXiIhGFt/lpSg4+T+uRfdd18hOQkREYRTf5SUEcvf2I+1PHC4h0ivlmlnoW3odwCtI0FfE/T4vdffH3EFNpGP9uSnonG5EsmIABH+aaVDclxcR6ZvlnY/gfAecd5CGYHkRUWxjadEw4nufF1EMUbOzYZw8SXYMorjA8iKKks7bpuLYt/N54AFRGHDYkChK0n9/DBl7k+HnMFhYuP9mPgwaYN1SJzsKScDyIhqBmpWJwORc4NMjEAO+cb2W1saLQYaTqU9A0fiHQKJieRGNwF+cj6alKZjeNAFaxznZcegrUrZ+IDsCScTyIhqBoeFzTP/CprtJS4niHQ/YIBqB8HoHh/u4n0p3FIsFA7eWwZifJzsKRQDLi4jikiE5CacWmjEwKUt2FIoADhsSUVzSzrsx5Z8/RaDfKzsKRQDLi4jiVqC3V3YEihAOGxIRke6wvIiISHdYXkREOqOmp6PjoXIYiwplR5GG5UVE42Z02HlIejQZjfCmKxBmk+wk0vCADSIat7Y7p6A/Q0HeU6dkR0kI2pkzcD59JqEvtMvyothgUNH+8DxkHuqHuutj2WkoRPYdJwCTEX7ZQShhsLwoZhj7BAy+gOwYNAb+U6dlR6AEw/Ki2BDQkPHiXtkpIk9RONUUURjwgA2iKOlbeh1c/72cF6MkCgNueRFFSbKrH0JJ5pYXURiwvIiipe4zpMjOQBQnOGxIRES6w/KiuKBYLOj55jyo06fIjkIEbeG18N9cJjtGXGN5UVxQjEacu0KFPydNdhQinJ9igXuKWXaMuMZ9XhQXAj09KNjwASB4nhjJl/nvdbIjxD1ueVH8CGhhOZLPmOdEx0PlUO05YQgVPYrJjM4V5VCumSU7CgnBo0ojjOVFMUvNzoaxID/6b2w2oT9DgWLU2cCEQYE3XUEgJXEna6XEobOfTkokHYumoatAQcE/t0T1ff1NJ5D31AndzdMnvF44nq2VHYMoKlheFLOyqpuQlZykuxIhoshjeVHM8re6ZEcgohjFfV5ERKQ7LC8iItIdlhcREekOy4uIiHSH5UVERLrD8iIiIt1heRERUdgZrFaoaZGbKJvlRUREYdd+fwlOPVgSsdfnScpERBR29vfPQphUROo6DywvGjdDUhIMuXZoLa0QAz7ZcYgoBmiHGiP6+hw2pPErnozPV+dCdejrEiJEpF/c8qLx+6IZM36pQWs/IzsJESUIlheNW6CnB4jwEAER0Vdx2JCIiHSH5UVERLrD8iIiIt1heRERfYVisQAGVXYMugyWFxHRn6lpaTj++LUQ8yM3MwSFB8uLiOjPAl4vHHV+mE53yo5Cl8FD5YmI/kx4vbDsqIdfdhC6LG55ERGR7oS9vNavXw9FUYbcHA5H8HEhBNavXw+n04nk5GQsWLAABw8eDHcMIiKKYxHZ8po1axZaW1uDt/379wcfe/rpp7Fp0yZs3rwZ9fX1cDgcuO2229DV1RWJKEREFIciUl5GoxEOhyN4y87OBjC41fUv//IvePzxx3H33XejpKQEL7/8Mnp7e/H6669HIgoREcWhiJRXY2MjnE4nioqKcO+99+LYsWMAgKamJrhcLlRWVgaXtVgsuOmmm1BbWxuJKBSDuu+Zj65l8wEAnSvK0b/4OsmJiEhvwn604bx58/DKK6+guLgYbW1t+PGPf4yKigocPHgQLpcLAGC324c8x26348SJE5d8Ta/XC6/XG/za4/GEOzZFkaIJKMrgvw1+AUUTcgMRRZB6xXQovf3wn2iWHSWuhL28Fi1aFPx3aWkpysvLMXXqVLz88suYP3/wr23ly99cfyaEuOi+r9q4cSOefPLJcEclSVJ/80Hw37Zf10lMQhR5J5ZmI7VVIP0lllc4RfxQ+dTUVJSWlqKxsTF41OGXW2Bfam9vv2hr7KvWrVsHt9sdvDU380NARPpQ+O9HkbX9c9kx4k7Ey8vr9eLQoUPIzc1FUVERHA4Hqqurg4/7fD7U1NSgoqLikq9hsViQlpY25EZE+qNOK4L42tXACCMt8UZra4fWyRk7wi3s5fXII4+gpqYGTU1N+OCDD/Ctb30LHo8Hy5cvh6IoqKqqwoYNG7Bt2zYcOHAAK1asQEpKCu6///5wRyGiGNN1VQ6ab0kBFM6PQOMT9n1eLS0tuO+++3D27FlkZ2dj/vz5qKurQ2FhIQDg0UcfRV9fH773ve+hs7MT8+bNw+9+9ztYrdZwRyGiGJP69ieYUG1GIKDJjkI6pwghdHeol8fjgc1mwwLcBaNiish7qMVT0X1FJlJ2fAIx4IvIexARJSq/GMBubIfb7R7TriBuu1+Cz2nD2auMUEycu5go2hSLBWp6uuwYFMP4m/kS1Jp9mLRHRcDP+aWJos1fMQsnKy2YuuEAApw6jobB8roUISD0UFzzr4KnKAVpb9QD3I9AccLy+WlM9toh+vpkR6EYxfLSOZ/NjN4cA3jyAMUTf6sLSqsLutshT1HD8tI5828/guO3slMQEUUXD9ggIiLdYXkREZHusLyIiEh3WF5ERKQ7LC8iItIdlhcREekOy4uIiHSH5UVERLrD8iIiIt1heRERke6wvIiISHdYXhRWhtRUGPPzAEWRHYWI4hjLi8LKP6cYR/5xElQb57knosjhrPIUVqbPjmP62Rxonm7ZUYgojrG8KKy0zk6gs1N2DCKKcxw2JCIi3WF5kS6cf6AcnSvKZcfQtY4Hy+G5b77sGERhwWHDBGQsKsSAYyKUus8AoY8LrSef9fNPrXFKbdegegOyYxCFBcsrAXXNtuPMbCMK61UIv192nFGxvFMvO4LuJf3nh7IjEIUNyysBpbzzKYp2WqDppLiIiC7E8kpAwuuF5vXKjkFENGbci0BRYUhKgsFqlR2DiOIEy4ui4txfX4PmlaWyYxBRnOCwIUVF5kdnMfFwkuwYRBQnWF4UFdqhRtkREp5qzwE0DdrZDtlRiMaNw4ZECaL5gWlwfatYdgyisOCWF1GCKNjuguLXwBMkKB6wvIgShNZ4THYEorDhsCEREekOy4uIokqdaMOpxypguPpK2VFIx1heRBRVYsCPlFYBpZezvNDYcZ8X0TgoRiOEpulmdv5YEOjpQfrLe6HJDkK6xi0vojFS7Tk4/k9zYbhqpuwoRAmH5UU0RqK3D9n7AjCcdcuOQpRwOGxINEaBri6kbPuA500RScAtLyIi0p24Ka+BW8vQf+d1smMQEcmlKOi+Zz6UufF9FYe4GTbsyzFhIFUB5y0nooSmGNCdZ4DZkwSz7CwRFDfllfZ6newIRETyBTQ4nq2VnSLi4mbYkIiIEgfLi4iIdIflRUREusPyIiK6QO/d83D2O+WyY0Rcx0Pl6P7rebJjjEncHLBBRBQuls4BCINJdoyISzoXgNmtz9PsWV5ERBdQd32MVNkhoiD1Nx/IjjBmHDYkIiLdYXkREZHusLyISDpDSgoMKSmyY5COsLyISLrWB69G+wOzZccgHeEBGwlCvWI6Oq/JxMStnyDQ3y87DtEQjr0eKP4AArKDkG6wvBKEf2IKPIUGTFTVqLyf0WFHoKcXga6uqLwf6Zv46ACE7BCkKyyvBKHs/RT5exGVv2wVoxFHV06BvUFD8psfRuEdiSjRcJ8XhZ3QNEx5oxPWD07KjkIxzuiwo31VBYyFBbKj0GUYC/IH/1/lOmRHAcAtL4oEIRA48Dn3X9DlKQoCpsH/Uowz/Pn/lSE2tnlYXkQkjb/VBcezLuhzgqLE4j/RDMezzTHz/yo2KpSIiCgEIZfX+++/jzvvvBNOpxOKouDNN98c8rgQAuvXr4fT6URycjIWLFiAgwcPDlnG6/Vi9erVyMrKQmpqKpYsWYKWlpZxfSNERJQ4Qi6vnp4ezJ49G5s3bx728aeffhqbNm3C5s2bUV9fD4fDgdtuuw1dXzlkuqqqCtu2bcOWLVuwZ88edHd3Y/HixdA0bezfCcUGRQEM0TkcnxIEP1M0DEUIMebTKxRFwbZt27B06VIAg1tdTqcTVVVV+MEPfgBgcCvLbrfjqaeewne+8x243W5kZ2fj1VdfxbJlywAAp0+fRkFBAXbs2IHbb7/9su/r8Xhgs9mwAHfBqMT/ZQv0RJTPRvNtqSj6lwPQPB7ZcSgO9C++Dh2zjMj76QdAgH/gxgu/GMBubIfb7UZaWlrIzw/rPq+mpia4XC5UVlYG77NYLLjppptQW1sLAGhoaMDAwMCQZZxOJ0pKSoLLkH6Z2tzIOqAh4PXKjkJh5r+5DIarZkb9fVOau5B50A8IHr9KfxHWow1dLhcAwG63D7nfbrfjxIkTwWXMZjPS09MvWubL51/I6/XC+5Vfhh7+RR+z/MeOI+XY8bifLUGxWKAYjQj09MiOEh2Kgra5FtiOGTHhs+i+deDTQ0j6NLrvSbEvIkcbKhecsyGEuOi+C420zMaNG2Gz2YK3ggKe0Ehyeb5xDU7+4+zEOT9JCORv+gjWbQ2ykxABCHN5ORyDZ15fuAXV3t4e3BpzOBzw+Xzo7Oy85DIXWrduHdxud/DW3NwczthEIZv4aQfyanqAse8y1h0x4IPwx8pZPpTowlpeRUVFcDgcqK6uDt7n8/lQU1ODiooKAEBZWRlMJtOQZVpbW3HgwIHgMheyWCxIS0sbciOSSTvUCKWWY1lEsoS8z6u7uxtHjx4Nft3U1IRPPvkEGRkZmDRpEqqqqrBhwwZMnz4d06dPx4YNG5CSkoL7778fAGCz2fDggw9i7dq1yMzMREZGBh555BGUlpbi1ltvDd93RkREcSvk8vroo4+wcOHC4Ndr1qwBACxfvhwvvfQSHn30UfT19eF73/seOjs7MW/ePPzud7+D1WoNPufZZ5+F0WjEPffcg76+Ptxyyy146aWXoEbpch1ENH6Bm66BuygJ6S/XJdTwKcWGcZ3nJQvP8yKSz39LGc5PMyPrFyyvRKVOKwK6eqC1tYf83PGe58WJeYloTIy/b0DW72WnIGkMKo49kIvMgwFM+L+hl9d4sbyIiCh0AQ1Tf3USorcXMuY94azyREQ0Jv7mFijJycB1pVGff5LlRUREY9ZT6sTxuybAYI7u8QccNiQiojFL3rUfUz9MgdbfH9X3ZXkREdGYBfr7gSgXF8BhQ6KIUoxGGFJTZccgkkNRBj//EZgDlOVFFEHeW65G06OzYUhKkh2FKOrUaUU4+r+ugrGoMOyvzfIiiqCUI2eQv7sfAd+A7CgRYUhNhee++TBOmSw7CsWis50oeM8Hca7z8suGiPu8iCLI33QCatMJ2TEiRjGb4Z5igO1zDo3SxbTOTpjea4jIeWAsLyIaM62zEwUb9kKHs8yRznHYMETer89F173zZccIG98dc+G5P36+H5KAxUWjoM6YhjMPl0MN0yWtWF4h0iwG+C3xc/VczaIEvx9jYQGMBfmSExFRXDKq0JIVwBCe358cNgxRytYPkCI7RBglb/8QyX/+d8vSAigBwP5/WqRmIqL4ox08DMdBhG3/F8uLgvL/33EgEAAv9E5EsY7lRUH+U6dlRyAiGhXu8yIiIt1heRERke6wvIiISHdYXkREpDssLyIi0h2WFxER6Q7Li4iIdIflRUREusPyIiIi3WF5UdgYiwphzHXIjkFECYDlRWFz/L48nLm9SHYMIkoAnNuQwmbya80Q/d6IXDU10SgWC1q/VwZ7XQ+UvZ/KjkMUc1heFDb+E82yI8QV83kBQ78fvNQj0cVYXvHIoAIBbv/omfB6kfHi3tgtLkXhFZRJKu7zijPG/Dyc/Kd5UKdPkR2F4pRisaDlsXL4by6THYUSGMsrzoieXqQfCkDp6pEdheKVpiH9iAZLW7fsJJTAOGwYZ7TOTljfqIv81ZAVBYbkZAT6vcMOURqSkiD8fgg/r8scKsVohGI2I9DbKzvKsITfj9TffKDLA3MUiwXA4LAs6Ru3vGhMjPl5+OKfZkO9YtpFjylGI44/ei367rhWQjL98y2YjabHZsOQlCQ7Stxpe7AM7X/Hz2U84JYXjUngvBt5uxxA29mLHhOahrw/9MPccl6Xf53LlvzFWeSJLAR8A7KjxJ2cj7qgCMTugTA0aooQ+jtkyOPxwGazYQHuglExRfW91bQ0wGSE1nEuqu9LRBRP/GIAu7EdbrcbaWlpIT+fw4Yhar9nFpr/fqbsGERECY3DhiHKqWkDzCYOhxERScTyCpHWeEx2BCJKAGpaGmDPgvbFCU46MAwOGxIRxaCBq6bgyD/YodpC3x+UCLjlRZekzClB6w1pcP7iUwR6eNIzUTSZPjuG4rYsaG6P7CgxiVtesUBRoJTNgjHPKTvJEEq/H6YuwTnsKOpUew6UOSVQjIn797Xm8QzupuCQ4bBYXjFAMZvRdHcaeq7Okx1liMCBz5H5q70xO9MDxS/flfk49i0rlORk2VEoRiXunzUxRHi9mPrsEYjePgRkhyGKAaa9f8K0A1Zo3Zw/kYbH8ooR2tkO2RGIYkagvx/o75cdg2IYhw2JaGQGFYaUFNkpiIZgeRHRiJTZM/HF/5oN1Z4jOwpREMuLiEaktp5FXo0foov7nyh2cJ8XEY3I72qD+d02HkxEMYVbXkREpDssL6ILGPPzcPY75dzHQxTDWF4jURQYp0yGmp4uOwlFk1GFL01J6NkdiGIdy2sEBosFjf+Qi975F1/qnuKX//hJOH9aC/+p07KjENEl8E/LEQS8Xkz7lQvo4OXsiYhiCbe8RiIEtKNN0Do7ZSeBOtEGZU4JDElJsqMQEUnH8tIJMTkPR++dAENmhuwoRETScdhQJ8TBoyj+6UT4z3AORCIilpdOiAEftLZ22TGIiGIChw2JiEh3WF5ERKQ7HDbUIbV4Ks5fkw0AsB08j8CBzyUnIiKKLpaXDvmzrei8YnCjOakjFaYDkgMREUVZyMOG77//Pu688044nU4oioI333xzyOMrVqyAoihDbvPnzx+yjNfrxerVq5GVlYXU1FQsWbIELS0t4/pGEonyx08w6UcfYNKPPoDp9x/LjkNEFHUhl1dPTw9mz56NzZs3X3KZO+64A62trcHbjh07hjxeVVWFbdu2YcuWLdizZw+6u7uxePFiaBrnsRi1gDZ4E0J2EiKiqAt52HDRokVYtGjRiMtYLBY4HI5hH3O73XjhhRfw6quv4tZbbwUA/PrXv0ZBQQHee+893H777aFGIiKiBBORow13796NnJwcFBcX46GHHkJ7+1/OT2poaMDAwAAqKyuD9zmdTpSUlKC2tnbY1/N6vfB4PENuRESUuMJeXosWLcJrr72GnTt34plnnkF9fT1uvvlmeL1eAIDL5YLZbEb6BZcZsdvtcLlcw77mxo0bYbPZgreCgoJwx45rHf+tHN6vz5Udg4gobMJeXsuWLcPXv/51lJSU4M4778Q777yDI0eO4O233x7xeUIIKIoy7GPr1q2D2+0O3pqbm8MdO+Z9OTGvYrGE/Fxjn4DBy4u4E1H8iPih8rm5uSgsLERjYyMAwOFwwOfzobOzc8jWV3t7OyoqKoZ9DYvFAssYfmmPiaLE5EEQX07MO6M1c/A6UyHktL1WF+F0RETRFfEZNjo6OtDc3Izc3FwAQFlZGUwmE6qrq4PLtLa24sCBA5csr2gxXDUTzf+zHGpWptQcwxGHvsCM/90Ef2sbRMVstDxWDkNqquxYRERShLzl1d3djaNHjwa/bmpqwieffIKMjAxkZGRg/fr1+OY3v4nc3FwcP34cP/zhD5GVlYVvfOMbAACbzYYHH3wQa9euRWZmJjIyMvDII4+gtLQ0ePShLAZPL2xfTITw+qTmGI7weuF3tQEAjB09sB1LhvD7JaciIpIj5PL66KOPsHDhwuDXa9asAQAsX74czz//PPbv349XXnkF58+fR25uLhYuXIg33ngDVqs1+Jxnn30WRqMR99xzD/r6+nDLLbfgpZdegqqqYfiWxs5//CTSjp9ErO8d0g4fhfXwUcTe4CYRUXQoQsTgDp7L8Hg8sNlsWIC7YFRMsuMQEVGI/GIAu7EdbrcbaWlpIT+fs8oTEZSyWei/87rBA4GIdIDlRUTozU/FuZlGQOGvBNIHzipPREh+qx7JimFwvkwiHeCfWRSz/DeXoWvZ/MsvSOMnBIuLdCWuykuxWGCcMnlMs1BQ7BmwqvBO5D4YIrpYXA0bGibl4fPv5mDG8wZojcdkx6FxSt7+IZJlhyCimBRX5SWaT2PGL1WI5tOyoxARUQTFVXkF+vuBQ42yYxARUYTF1T4vIiJKDCwvIiLSHZYXEY2b4aqZwPyrZMegBMLyIqJxO1uWjtavTZAdgxJIXB2wQURyZL7+MRRVjfkrMlD8YHkR0bgJr5eX6KGo4rAhEVGYGaxWGL5yDUMKP5YXEVGYub5dCtfyUtkx4hqHDYmIwix3dwcAgFMdRw7Li2KWmp0NxWKGv+WU7ChEIdEOHpYdIe5x2JBiVseiaWhaXig7BhHFIG55UczKqm5CZmpyzA+99HxrHvwWBbbX6mRHIUoYLC+KWf5Wl+wIo2LwC6gGXndMD9TpUwCAl0yKAywvonFKfvND2RFolE79lQNKALCzvHSP5UWUQAxXzcSJJRkAgOxP/Uj6z8Qq3rzXDgNCxPxQNF0ey4sogRi6+mA9MTgXhuWsV3Ka6NPOdsiOEFuuK4WhdwCBA5/LThIylleMUCwWiAE/EODfhBQ5/qYTmNh0QnYMkkSxWCB8PkAM/gHTeoMVSR0C6QckBxsDHiofAxSLBSd+UAbfbdfIjkJEccrosKPpn64dvHzNn+U9/wkyt+yTmGrsuOUVA8SAH44PB5Dc1MmxeCKKiEBXNxx7NRjaO4Oz/wd6e6VmGg+W12gpCtSJExHo7oEY8IX3tQMazO/Ws7jo8gwq1HQbtE43h5gpJIGeHiT914fwyw4SJhw2HCU1MwONj82EKJt5+YWJIkSdWogjj82AOpUzj1BiY3mNUqCrG0Vv9UH9olV2lFEzTp6Ec39fDjU9XXYUCpe2syja3ge0nZWdhEgqDhuOkvB6ofzxE10N7QmLGX05CmA2yY5CYaJ5PDDs0dfnMNqMBfkQXV3QzrtlR6EI4pZXHNMOH0XeT2qhtbXLjkIUFYrJjKMPF6D7phmyo1CEccuLiOKG8A9g6itngHNubp3GOW550agYcx0wlMwEFE5AqweKyQzD1VdCnWiTHQVqdvbguUUGNfJvJgS0w0ehnTkT+fciqVheNCqe+YU4tiwdihqFX0A0boaJNjT+bRq04kmyo8B71SQcvT8dhtQU2VEojnDYkEbF+vtDSKtLgd8fL2eJxDet4xxmPGtCoONc8IRUWcx1n6P4T1b4u7slJ6F4wvKiUdE8HsDjkR2DRiugwX/qtOwUAAZPjg309MiOQXGGw4ZERKQ7LC8iItIdlhcREekOy4tIJwypqTBYrWN4ojo4RdgoD1U3pKZCTUsL/X2IoojlRaQTZ+6/CqceKg35eeqUSTjyw5mjnsz3zL1XofkfSkJ+H6Jo4tGGRDqR88cOCLMx5EPfRdtZFG23jXoy35y9HQhYTBChRySKGpYXkU5ofzoypucFurpCmsx3rO9DFE0cNiQiIt1heRHpiDE/D67/XgFjfp7sKERSsbxGoigwlMyEmp0tOwkRAEAkW9BdGIBItsiOQiQVy2sEBosFX/xNOnrnTJYdhYiIvoIHbIwg4PVi+uYTCHi6pE9umoh6756H7lwVOT+rlR0lZgSOt2DmJi+0Nl7ygxIby2skQsTM5KaJKOmMD4A5pOeoM6ZBS08B6j6LTKgoU4unwp85AcreTwEAYsAHf8spyamI5GN5Ucwy/GEfQr0CVGdZFjyFBuTXRSRS1J2/JhvnpxlQUKcAgmdeEX2J5UVxZeLWTzDRZIqbYV7b9k9gM5kQYHERDcHyorgS6O8H+vtlxwibePt+iMKFRxtKppjMUCfaZMcgItIVlpdkAzeU4uijV8KQmio7ChGRbnDYULKkIy4U+rIhvF7ZUYiIdIPlJZm/5RQMLac4gzcRUQg4bEhERLrD8iKKAeqVxWhbXcGDd4hGieVFuqfac6BeWQwoiuwoYycEFI4dE40ay4t0r+e6yfjibzKhmEObSiqWaIcakbO5Ftp5t+woRLoQUnlt3LgRc+fOhdVqRU5ODpYuXYrDhw8PWUYIgfXr18PpdCI5ORkLFizAwYMHhyzj9XqxevVqZGVlITU1FUuWLEFLS8v4vxtKSKk1n2Pacyd4xCZRAgmpvGpqarBy5UrU1dWhuroafr8flZWV6OnpCS7z9NNPY9OmTdi8eTPq6+vhcDhw2223oaurK7hMVVUVtm3bhi1btmDPnj3o7u7G4sWLoWmjvVB5DDOoEF+7GsbCAtlJEobm8XACZaIEowgx9knTzpw5g5ycHNTU1ODGG2+EEAJOpxNVVVX4wQ9+AGBwK8tut+Opp57Cd77zHbjdbmRnZ+PVV1/FsmXLAACnT59GQUEBduzYgdtvv/2y7+vxeGCz2bAAd8GomMYaPyIUiwVN//NaOP/oh/ndetlxiIhikl8MYDe2w+12Iy0tLeTnj2ufl9s9OD6fkZEBAGhqaoLL5UJlZWVwGYvFgptuugm1tYPXZGpoaMDAwMCQZZxOJ0pKSoLLXMjr9cLj8Qy5xSrh9WLqTw/Csis+LslBRBSLxlxeQgisWbMG119/PUpKSgAALpcLAGC324csa7fbg4+5XC6YzWakp6dfcpkLbdy4ETabLXgrKIjtITnN4+H+FyKiCBpzea1atQqfffYZ/uM//uOix5QLDlkWQlx034VGWmbdunVwu93BW3Nz81hjExFRHBhTea1evRpvvfUWdu3ahfz8/OD9DocDAC7agmpvbw9ujTkcDvh8PnR2dl5ymQtZLBakpaUNuRERUeIKqbyEEFi1ahW2bt2KnTt3oqioaMjjRUVFcDgcqK6uDt7n8/lQU1ODiooKAEBZWRlMJtOQZVpbW3HgwIHgMhRdalYmOpeXw5ifJzsKhcA4ZTLOf7scBqtVdhSiqAtpYt6VK1fi9ddfx/bt22G1WoNbWDabDcnJyVAUBVVVVdiwYQOmT5+O6dOnY8OGDUhJScH9998fXPbBBx/E2rVrkZmZiYyMDDzyyCMoLS3FrbfeGv7vkC5LsVjQk6cgK9kiOwqFIDAhCd15CjLNsXXELVE0hHSo/KX2Sb344otYsWIFgMGtsyeffBI///nP0dnZiXnz5uFnP/tZ8KAOAOjv78f3v/99vP766+jr68Mtt9yC5557btQHYsTyofJERHR54z1Uflznecky3vJSJ9rQ+rezkPv7M9AONUYgIRERjUTqeV56JhL2Oyci0r+EvBildt4N+7/WIg4moyIiSkjc/iAiIt1heemQMc8J8bWroRgTcsOZKGyMuY7BnyWTfi+nE21K2azB6+dJxvLSIW+xA8e/ngwlOVl2lISnGI36vghmgvMV5+L44mQYkpNkR9GNUwttaC/PlB0jMfd56Z1xzwFM25cM7SuXmaHoU+05OLZyKop+cx6BTw/JjkNjoNYexLRP+bMUivyf7wcCAQQk52B56ZAY8EE775MdI+GJ3j5k7wvAcNYt/QeZxoY/S6ELxEjRs7wSjMFqhfD5OOt9GAS6upCy7QP4ZQchSkDc55VAFJMZTY+Uou+22bKjEBGNC8srgQj/ACb9rhcTDrbJjkIxyGC14vwD5VCnFV1+YSLJOGyYSISA8sdPOMxFw1KMRnTnK8iYwKNYKfaxvIgIAKB1diJ/Yy0PPiFd4LAhERHpDssrDihGI9Qri6FOtMmOQkQUFSyvOGCwpeHI32VioIQ72okoMXCfVxzQOt2YsbkFgbPnuL+CiBICyyseBDT4TzTLTkFEFDUcNiQiIt1heRERke6wvBKJQYXvjrlQr5guOwkR0biwvBKIoqpom2NC7+SJsqMQEY0LD9hIIGLAh0lPfQShabKjEBGNC7e8EowY8AEBlhfR5aiZGTj/QDmM+Xmyo1xEnWgbzFaQLzuKNCwvIqJhKGYzugoViJQk2VEuZrEMZrOmyE4iDYcNiYiG4W91oeDHLsTiOIXW1o6CH7fHZLZo4ZYXkSTG/Dy0r6qAMdchOwqR7rC8iGRRFARMAAz8MUwkanY21BnTAEWRHUXX+FNDJIm/uQWOZ2vhP3VadhSKou6KInzx7WwoRpPsKLrG8kpwvXfPw9l/KB/Xa6jFU3HqsQoYHfYwpSKKXxNqDmPaL1oGj/ylMWN5SaBmZkBUzIYhSf5RTGa3H8nnxjcXveL1IemMgBgYCFMqudS0NIivXQ1DaqrsKBSHtPNuTqQdBjzaUILApFw0LU1B8TEbAq5+qVmMv28Y94fAf6IZmS80x8+RT7k5OLY0GTNOZyHQ1CM7DRENg+Ulw4FGTH9qAvznOmUnoWEEvjiO4p+cg7/TLTsKEV0Chw0lEAM+aB3nACFkR7k8gwrf7XMGj45KEMLvH/z/w5lIiGIWy4uGZUhJgWKxDE7mO9eM3qnpsiMRRY1iscCQkrizV0SaYjLDYJ0wrtdgedGwmldfjfPfumZwMt+fNsDy7seyIxFFTec916Jl1dWyY8Qt38KrcOz7V47rNbjPK86omRk4t6gYmb8/Dn+ra8yv43y/B0Z3HzQAwusNX0AiHcj8+BxsafKPBo5XyUfake+14vg4XoPlFWeUpCR4igzImDC+IQ9l76fxc/QgUYi0g4fB+S8ix3/8JIxN4zu1huUVZ/ynTqPgx63Q9HAwCBHRGHGfVzxicRFRnGN5EcUwo8MOdVqR7BhEMYflRRTDzi0sQtPf5HIGcqILcJ9XHOn55jz0ZxiQ+cu9sqNQmKT/7ggy9qTAz6FgoiFYXnHE7PZDGPi/NJ5oHeeAjnOyYxDFHP6miyOm9xrAKwQRUSLgPi8iItIdlhcREekOy4uIaIwUk5kT+ErC8iIiGqO+26/G8e9fDcVklh0l4fCADSKiMUr9/AzyutMh/OObp49Cx/KKIQarFUpKMrS2dtlRiGgUtKNNUI82yY6RkDhsGEO6br8Sx743DTCosqMQEcU0llcMsdW1oOg3cXD5eYOKc39fDlExW3YS0hH/LWXwvzeJcznSqHDYMIb4W04BLbJTjJ9iUOBPUhAwq+A2JI2WZjZgRtoZNKt5sqOQDrC8KOyE34+c52plxyCdsbxTj+PvAMBR2VFIBzhsSEREusPykki5ZhaMUybLjkFEpDssr+EY1MhfP0lRcPKvbDg33xHZ9yEiikPc53UhRUHr/5gH2zENKds+iNz7CIHJzx2C8PkQiNy7EBHFJZbXhYRA+mE/kl29iPTl/7TOzgi/AxFRfGJ5DSPpvz6MeHEREdHYcZ8XERHpTkjltXHjRsydOxdWqxU5OTlYunQpDh8+PGSZFStWQFGUIbf58+cPWcbr9WL16tXIyspCamoqlixZgpaWODg7l4iIoiKk8qqpqcHKlStRV1eH6upq+P1+VFZWoqenZ8hyd9xxB1pbW4O3HTt2DHm8qqoK27Ztw5YtW7Bnzx50d3dj8eLF0DSdT4tERCFRjEYYHXZeUoRCFtI+r3fffXfI1y+++CJycnLQ0NCAG2+8MXi/xWKBwzH8IeButxsvvPACXn31Vdx6660AgF//+tcoKCjAe++9h9tvvz3U74GIdEotyMPhVbko/lUatEONsuOQjoxrn5fb7QYAZGRkDLl/9+7dyMnJQXFxMR566CG0t//lEh8NDQ0YGBhAZWVl8D6n04mSkhLU1g4/pZDX64XH4xlyi3WBG67B+W+XR/58sa/w3TEXXffOv/yCRDEi0HYG07b0QLS4ZEchnRlzeQkhsGbNGlx//fUoKSkJ3r9o0SK89tpr2LlzJ5555hnU19fj5ptvhtfrBQC4XC6YzWakp6cPeT273Q6Xa/gP8MaNG2Gz2YK3goKCscaOGs1iwECUrw6uJSnw2hSoM6bx0uSkC4HeXoj6/Qh0dcmOQjoz5kPlV61ahc8++wx79uwZcv+yZcuC/y4pKcGcOXNQWFiIt99+G3ffffclX08IAeUSWynr1q3DmjVrgl97PJ6YLzDTew3Ifi+675n85oewTp6Ez//RiRm/MgB/OhLdAEREUTKmLa/Vq1fjrbfewq5du5Cfnz/isrm5uSgsLERj4+B4tsPhgM/nQ+cFJ+i2t7fDbrcP+xoWiwVpaWlDbjQ87ZQLM55rgzh2UnaUsFDtOTj9/QqoxVMvuUzgpmvQ9o8V3OlPlEBCKi8hBFatWoWtW7di586dKCq6/EXjOjo60NzcjNzcXABAWVkZTCYTqqurg8u0trbiwIEDqKioCDE+XUgM+KAdbUKgv192lPDw+2F2CygD/ksuYugbXAaCE20RJYqQhg1XrlyJ119/Hdu3b4fVag3uo7LZbEhOTkZ3dzfWr1+Pb37zm8jNzcXx48fxwx/+EFlZWfjGN74RXPbBBx/E2rVrkZmZiYyMDDzyyCMoLS0NHn0YUV8OTQrOoaEHWsc5ZP1iLy5dXQA+3I/0D8FZUYgSSEjl9fzzzwMAFixYMOT+F198EStWrICqqti/fz9eeeUVnD9/Hrm5uVi4cCHeeOMNWK3W4PLPPvssjEYj7rnnHvT19eGWW27BSy+9BFWN/HV3+5bMxflpRuRu2ssCIyLSKUUI/f0G93g8sNlsWIC7YFRMIT1XmVOC3rwUJL9VHzvlZVDhX3g1LCfOQTvaJDsNEVHE+cUAdmM73G73mI5j0OXEvF/2rR8DoY8V1e+DqR4jD0NFmWI04MTXArAbrUhqHJAdh4go4vwY/F031u0nXW55tbS0xPyh8kREdHnNzc2XPWp9OLosr0AggMOHD+PKK69Ec3MzD50fxpfnwnH9DI/r5/K4jkbG9TOyy60fIQS6urrgdDphMIR+1pYuhw0NBgPy8vIAgOd9XQbXz8i4fi6P62hkXD8jG2n92Gy2Mb8ur+dFRES6w/IiIiLd0W15WSwWPPHEE7BYLLKjxCSun5Fx/Vwe19HIuH5GFun1o8sDNoiIKLHpdsuLiIgSF8uLiIh0h+VFRES6w/IiIiLd0W15PffccygqKkJSUhLKysrwhz/8QXakqFu/fj0URRlyczgcwceFEFi/fj2cTieSk5OxYMECHDx4UGLiyHv//fdx5513wul0QlEUvPnmm0MeH8068Xq9WL16NbKyspCamoolS5agpaUlit9F5Fxu/axYseKiz9T8+fOHLBPP62fjxo2YO3curFYrcnJysHTpUhw+fHjIMon8GRrN+onWZ0iX5fXGG2+gqqoKjz/+OPbt24cbbrgBixYtwsmT8XH14FDMmjULra2twdv+/fuDjz399NPYtGkTNm/ejPr6ejgcDtx2223o6uqSmDiyenp6MHv2bGzevHnYx0ezTqqqqrBt2zZs2bIFe/bsQXd3NxYvXgxN06L1bUTM5dYPANxxxx1DPlM7duwY8ng8r5+amhqsXLkSdXV1qK6uht/vR2VlJXp6eoLLJPJnaDTrB4jSZ0jo0HXXXScefvjhIffNnDlTPPbYY5ISyfHEE0+I2bNnD/tYIBAQDodD/OQnPwne19/fL2w2m/i3f/u3KCWUC4DYtm1b8OvRrJPz588Lk8kktmzZElzm1KlTwmAwiHfffTdq2aPhwvUjhBDLly8Xd9111yWfk0jrRwgh2tvbBQBRU1MjhOBn6EIXrh8hovcZ0t2Wl8/nQ0NDAyorK4fcX1lZidraWkmp5GlsbITT6URRURHuvfdeHDt2DADQ1NQEl8s1ZD1ZLBbcdNNNCbmegNGtk4aGBgwMDAxZxul0oqSkJGHW2+7du5GTk4Pi4mI89NBDaG9vDz6WaOvH7XYDADIyMgDwM3ShC9fPl6LxGdJdeZ09exaapsFutw+53263w+VySUolx7x58/DKK6/gt7/9LX75y1/C5XKhoqICHR0dwXXB9fQXo1knLpcLZrMZ6enpl1wmni1atAivvfYadu7ciWeeeQb19fW4+eab4fV6ASTW+hFCYM2aNbj++utRUlICgJ+hrxpu/QDR+wzpclZ5AFAUZcjXQoiL7ot3ixYtCv67tLQU5eXlmDp1Kl5++eXgDlKup4uNZZ0kynpbtmxZ8N8lJSWYM2cOCgsL8fbbb+Puu+++5PPicf2sWrUKn332Gfbs2XPRY/wMXXr9ROszpLstr6ysLKiqelFDt7e3X/TXUKJJTU1FaWkpGhsbg0cdcj39xWjWicPhgM/nQ2dn5yWXSSS5ubkoLCxEY2MjgMRZP6tXr8Zbb72FXbt2DblQIj9Dgy61foYTqc+Q7srLbDajrKwM1dXVQ+6vrq5GRUWFpFSxwev14tChQ8jNzUVRUREcDseQ9eTz+VBTU5Ow62k066SsrAwmk2nIMq2trThw4EBCrreOjg40NzcjNzcXQPyvHyEEVq1aha1bt2Lnzp0oKioa8niif4Yut36GE7HP0KgP7YghW7ZsESaTSbzwwgviT3/6k6iqqhKpqani+PHjsqNF1dq1a8Xu3bvFsWPHRF1dnVi8eLGwWq3B9fCTn/xE2Gw2sXXrVrF//35x3333idzcXOHxeCQnj5yuri6xb98+sW/fPgFAbNq0Sezbt0+cOHFCCDG6dfLwww+L/Px88d5774mPP/5Y3HzzzWL27NnC7/fL+rbCZqT109XVJdauXStqa2tFU1OT2LVrlygvLxd5eXkJs36++93vCpvNJnbv3i1aW1uDt97e3uAyifwZutz6ieZnSJflJYQQP/vZz0RhYaEwm83i2muvHXKoZqJYtmyZyM3NFSaTSTidTnH33XeLgwcPBh8PBALiiSeeEA6HQ1gsFnHjjTeK/fv3S0wcebt27RIALrotX75cCDG6ddLX1ydWrVolMjIyRHJysli8eLE4efKkhO8m/EZaP729vaKyslJkZ2cLk8kkJk2aJJYvX37R9x7P62e4dQNAvPjii8FlEvkzdLn1E83PEC+JQkREuqO7fV5EREQsLyIi0h2WFxER6Q7Li4iIdIflRUREusPyIiIi3WF5ERGR7rC8iIhId1heRESkOywvIiLSHZYXERHpDsuLiIh05/8D3C0uzw92B18AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0, :, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the PhotonLoss can be implemented directly in python + jax as the optax follows the same method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Training Loop for GAP\n",
    "* [Flax Training with TrainState](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial3/Activation_Functions.html#Training-a-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpu', 0, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.local_devices()[0].platform, jax.process_index(), jax.process_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.reshape((jax.local_device_count(), -1) + img.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.\n"
     ]
    }
   ],
   "source": [
    "from flax.training import train_state, checkpoints\n",
    "import optax\n",
    "from optax.contrib import reduce_on_plateau\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_devices()[0].platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Trainer on GPU and make necessary updates for TPU and test on Kaggle\n",
    "\n",
    "\n",
    "#### The following strategy is from huggingface is [nice](https://github.com/huggingface/transformers/blob/main/examples/flax/vision/run_image_classification.py#L469), they use pmap!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAPXTrainer:\n",
    "    ''' \n",
    "    Credits for Trainer Module : https://github.com/phlippe/jax_trainer\n",
    "    '''\n",
    "    def __init__(self, root_dir, gradient_clip_val, epochs, dataloader, model: nn.Module, lr = 1e-4, seed = 42, channels = 1):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.gradient_clip_val = gradient_clip_val\n",
    "        self.max_epochs = epochs\n",
    "        self.img = next(iter(dataloader))[:,:,:,channels:]\n",
    "        self.learning_rate= lr\n",
    "        self.seed = seed\n",
    "        self.channels = channels\n",
    "        self.platform = jax.local_devices()[0].platform\n",
    "        self.model = model\n",
    "        self.logger = SummaryWriter(log_dir= self.root_dir)\n",
    "        self.earlystop = EarlyStopping(min_delta= 1e-3, patience= 10)\n",
    "        self.init_training()\n",
    "        self.init_model()\n",
    "        if self.platform == 'gpu': \n",
    "            print(f'GPU detected with {jax.process_count()} Device(s).')\n",
    "        elif self.platform == 'tpu':\n",
    "            print(f'TPU detected with {jax.process_count()} Device(s).')\n",
    "        else: \n",
    "            print(f'CPU detected, Training will be slow!.')\n",
    "\n",
    "\n",
    "    def init_model(self):\n",
    "        ''' \n",
    "        Initializes the Unet model for GAP training\n",
    "        '''\n",
    "        init_rng = jax.random.key(self.seed)\n",
    "        params = self.model.init(init_rng, self.img)\n",
    "        self.state = train_state.TrainState(step=0,\n",
    "                                            apply_fn=self.model.apply,\n",
    "                                            params=params,\n",
    "                                            tx=None,\n",
    "                                            opt_state=None)\n",
    "    \n",
    "    def init_optimizer(self):\n",
    "        ''' \n",
    "        Initializes adam optimizer with gradient clipping and learning rate schedule to reduce on plateau\n",
    "        '''\n",
    "        tx = optax.chain(optax.clip(self.gradient_clip_val),\n",
    "                         optax.adam(learning_rate= self.learning_rate),\n",
    "                         optax.contrib.reduce_on_plateau(factor = 0.5))\n",
    "        \n",
    "        self.state = train_state.TrainState.create(apply_fn= self.model.apply_fn,\n",
    "                                                   params= self.state.params,\n",
    "                                                   tx= tx)\n",
    "    \n",
    "    def photonLoss(self, result, target):\n",
    "        ''' \n",
    "        GAP PhotonLoss\n",
    "        '''\n",
    "        expEnergy = jnp.exp(result)\n",
    "        perImage = -jnp.mean(result*target, axis = (-1, -2, -3), keepdims=True)\n",
    "        perImage += jnp.log(jnp.mean(expEnergy, axis = (-1, -2, -3), keepdims= True))*jnp.mean(target, axis = (-1, -2, -3), keepdims= True)\n",
    "\n",
    "        return jnp.mean(perImage)\n",
    "    \n",
    "    def init_training(self):\n",
    "        def train_step(state, batch):\n",
    "            '''\n",
    "            Computes loss and applies a gradietn step\n",
    "            '''\n",
    "            def compute_loss(params):\n",
    "                ''' \n",
    "                Computes Photon Loss\n",
    "                '''\n",
    "                result = state.apply_fn(params, batch[:,:,:,self.channels:])\n",
    "                loss = self.photonLoss(result, batch[:,:,:,:self.channels])\n",
    "                return loss\n",
    "\n",
    "            grad_fn = jax.value_and_grad(compute_loss)\n",
    "            loss, grads = grad_fn(state.params)\n",
    "\n",
    "            state = state.apply_gradients(grads = grads)\n",
    "            return state, loss\n",
    "        \n",
    "        def eval_step(state, batch):\n",
    "            ''' \n",
    "            Computes Loss\n",
    "            '''\n",
    "            result = state.apply_fn(state.params, batch[:,:,:,self.channels:])\n",
    "            loss = self.photonLoss(result, batch[:,:,:,:self.channels])\n",
    "            return loss\n",
    "        \n",
    "        self.train_step = jax.jit(train_step)\n",
    "        self.eval_step = jax.jit(eval_step)\n",
    "    \n",
    "    def train_epoch(self, train_loader, epoch):\n",
    "        ''' \n",
    "        Trains the model for the given training dataloader\n",
    "        '''\n",
    "        avg_loss = 0\n",
    "        for batch in tqdm(train_loader, desc='Training', leave=False):\n",
    "            self.state, loss = self.train_step(self.state, batch)\n",
    "            avg_loss += loss\n",
    "        avg_loss /= len(train_loader)\n",
    "        self.logger.add_scalar('Loss/train ', avg_loss.item(), global_step=epoch)\n",
    "\n",
    "    def eval_model(self, data_loader):\n",
    "        ''' \n",
    "        Evaluates the model for the given validation dataloader\n",
    "        '''\n",
    "        avg_ploss, count = 0, 0\n",
    "        for batch in data_loader:\n",
    "            ploss = self.eval_step(self.state, batch)\n",
    "            avg_ploss += ploss * batch[0].shape[0]\n",
    "            count += batch[0].shape[0]\n",
    "        eval_ploss = (avg_ploss / count).item()\n",
    "        return eval_ploss\n",
    "\n",
    "    def save_model(self, step=0):\n",
    "        ''' \n",
    "        Save the checkpoints of the model \n",
    "        '''\n",
    "        checkpoints.save_checkpoint(ckpt_dir=self.root_dir,\n",
    "                                    target=self.state.params,\n",
    "                                    step=step,\n",
    "                                    overwrite=True)\n",
    "\n",
    "    def load_model(self):\n",
    "        ''' \n",
    "        Loads the checkpoints of the model and creates its state\n",
    "        '''\n",
    "        state_dict = checkpoints.restore_checkpoint(ckpt_dir=f'{self.root_dir}.ckpt',\n",
    "                                                    target=self.state.params)\n",
    "        self.state = train_state.TrainState.create(apply_fn=self.state.apply_fn,\n",
    "                                                   params=state_dict,\n",
    "                                                   tx=self.state.tx)\n",
    "\n",
    "    def checkpoint_exists(self):\n",
    "        return os.path.isfile(f'{self.root_dir}.ckpt')\n",
    "\n",
    "    def train_model(self, train_loader, val_loader):\n",
    "        self.init_optimizer()\n",
    "        best_eval = 1e6\n",
    "        for epoch_idx in tqdm(range(1, self.max_epochs +1)):\n",
    "            self.train_epoch(train_loader, epoch=epoch_idx)\n",
    "            if epoch_idx % 1 == 0:\n",
    "                eval_ploss = self.eval_model(val_loader)\n",
    "                self.logger.add_scalar('Loss/val', eval_ploss, global_step=epoch_idx)\n",
    "                self.earlystop = self.earlystop.update(eval_ploss)\n",
    "                if eval_ploss <= best_eval:\n",
    "                    best_eval = eval_ploss\n",
    "                    self.save_model(step=epoch_idx)\n",
    "                if self.earlystop.should_stop:\n",
    "                    print(f'Met early stopping criteria, breaking at epoch {epoch_idx}')\n",
    "                    break\n",
    "            self.logger.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 3\n",
    "earlystop = earlystop.update(loss)\n",
    "earlystop.should_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.apply of UN(\n",
       "    # attributes\n",
       "    levels = 3\n",
       "    channels = 1\n",
       "    depth = 5\n",
       "    start_filts = 64\n",
       "    up_mode = 'transpose'\n",
       "    merge_mode = 'add'\n",
       ")>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UN(3, 1)\n",
    "params = model.init(jax.random.key(5),(jnp.ones((1, 32, 32, 1))))\n",
    "train_state.TrainState(step=0,\n",
    "                       apply_fn=model.apply,\n",
    "                       params= params,\n",
    "                       tx=None,\n",
    "                       opt_state=None).apply_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
