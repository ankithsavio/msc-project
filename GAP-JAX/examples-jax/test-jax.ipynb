{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tifffile import imread, imsave\n",
    "import torch\n",
    "import torch.utils.data as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/mnt/c/Users/ankit/Desktop/Msc AIML/msc-project/GAP-JAX')\n",
    "from gap_jax.BinomDataset_JAX import BinomDataset\n",
    "from  gap_jax.GAP_JAX_Trainer import Trainer\n",
    "from gap_jax.GAP_UNET_ResBlock_JAX import UN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = imread('/mnt/c/Users/ankit/Desktop/Msc AIML/Data/convallaria/trainingDataGT.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/c/Users/ankit/Desktop/Msc AIML/Data/checkpoints/models/',\n",
       " 'm40tom5-256x256-jax-v1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def psnrToString(inp):\n",
    "    if inp < 0:\n",
    "        return 'm'+str(-inp)\n",
    "    else:\n",
    "        return str(inp)\n",
    "\n",
    "minpsnr = -40\n",
    "maxpsnr = -5\n",
    "\n",
    "name = psnrToString(minpsnr)+\"to\"+psnrToString(maxpsnr)+\"-256x256-jax-v1\"\n",
    "CHECKPOINT_PATH = '/mnt/c/Users/ankit/Desktop/Msc AIML/Data/checkpoints/models/'\n",
    "CHECKPOINT_PATH, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "maxepochs = 20 # train longer for better results\n",
    "\n",
    "# Create pytorch dataset\n",
    "dataset = BinomDataset(data = data[:round(data.shape[0]*0.9)], windowSize = 256, minPSNR = minpsnr, maxPSNR = maxpsnr)\n",
    "val_dataset = BinomDataset(data = data[round(data.shape[0]*0.9):], windowSize = 256, minPSNR = minpsnr, maxPSNR = maxpsnr)\n",
    "\n",
    "# Create pytorch dataloader for training and validation sets\n",
    "train_loader = dt.DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True, pin_memory=False, num_workers=12, collate_fn= lambda batch: np.array(batch)) ## Changing the batch size from 32 to 16 to fit inside the gpu\n",
    "val_loader = dt.DataLoader(val_dataset, batch_size=8, shuffle=False, drop_last=False,  pin_memory=False, num_workers=12, collate_fn= lambda batch: np.array(batch))\n",
    "\n",
    "img =  next(iter(val_loader))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UN(channels = 1, levels=10, depth=3, start_filts=28, up_mode = 'transpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected with 1 Device(s).\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(root_dir= os.path.join(CHECKPOINT_PATH, name),\n",
    "                  gradient_clip_val=0.5,\n",
    "                  epochs= maxepochs,\n",
    "                  dataloader= train_loader,\n",
    "                  model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957ba1f962564969b31b10f1da89af31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankith/anaconda3/envs/rsenv/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683d8014e6a243819d9a4ff3cc93e118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "reduce_on_plateau.<locals>.update_fn() missing 1 required keyword-only argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/ankit/Desktop/Msc AIML/msc-project/GAP-JAX/gap_jax/GAP_JAX_Trainer.py:152\u001b[0m, in \u001b[0;36mTrainer.train_model\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    150\u001b[0m best_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e6\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    154\u001b[0m         eval_ploss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_model(val_loader)\n",
      "File \u001b[0;32m/mnt/c/Users/ankit/Desktop/Msc AIML/msc-project/GAP-JAX/gap_jax/GAP_JAX_Trainer.py:109\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, train_loader, epoch)\u001b[0m\n\u001b[1;32m    107\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    111\u001b[0m avg_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m/mnt/c/Users/ankit/Desktop/Msc AIML/msc-project/GAP-JAX/gap_jax/GAP_JAX_Trainer.py:89\u001b[0m, in \u001b[0;36mTrainer.init_training.<locals>.train_step\u001b[0;34m(state, batch)\u001b[0m\n\u001b[1;32m     86\u001b[0m grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(compute_loss)\n\u001b[1;32m     87\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m grad_fn(state\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m---> 89\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, loss\n",
      "File \u001b[0;32m~/anaconda3/envs/rsenv/lib/python3.10/site-packages/flax/training/train_state.py:102\u001b[0m, in \u001b[0;36mTrainState.apply_gradients\u001b[0;34m(self, grads, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m   grads_with_opt \u001b[38;5;241m=\u001b[39m grads\n\u001b[1;32m    100\u001b[0m   params_with_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m--> 102\u001b[0m updates, new_opt_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m  \u001b[49m\u001b[43mgrads_with_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_with_opt\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m new_params_with_opt \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params_with_opt, updates)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# As implied by the OWG name, the gradients are used directly to update the\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# parameters.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rsenv/lib/python3.10/site-packages/optax/transforms/_combining.py:73\u001b[0m, in \u001b[0;36mchain.<locals>.update_fn\u001b[0;34m(updates, state, params, **extra_args)\u001b[0m\n\u001b[1;32m     71\u001b[0m new_state \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(state, update_fns):\n\u001b[0;32m---> 73\u001b[0m   updates, new_s \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m   new_state\u001b[38;5;241m.\u001b[39mappend(new_s)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updates, \u001b[38;5;28mtuple\u001b[39m(new_state)\n",
      "\u001b[0;31mTypeError\u001b[0m: reduce_on_plateau.<locals>.update_fn() missing 1 required keyword-only argument: 'value'"
     ]
    }
   ],
   "source": [
    "trainer.train_model(train_loader= train_loader,\n",
    "                    val_loader= val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
